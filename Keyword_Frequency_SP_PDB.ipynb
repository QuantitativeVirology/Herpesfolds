{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34d0324c",
   "metadata": {},
   "source": [
    "# Keyword_Frequency_SP_PDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680c9bec",
   "metadata": {},
   "source": [
    "Overview needed input files: \n",
    "##### Frequency_#1: \n",
    "    \"filename\"_FL_against_pdb_nosymbol_hits.tsv\n",
    "##### Extract_Keywords_HomologyTable_#2: \n",
    "    \"filename2\".xlsx \n",
    "##### Subtraction_Keywords_#3: \n",
    "    \"filename\"_freq.tsv (Output1 Frequency_#1)\n",
    "    \"filename\"_freq-1.tsv (Output2 Frequency_#1)\n",
    "    \"filename2\"_keywords.tsv (Output Extract_Keywords_HomologyTable_#2)\n",
    "                             \n",
    "##### File_Merging_#4: \n",
    "    \"filename\"_freq-withoutHF.tsv (Output1 Subtraction_Keywords_#3)\n",
    "    \"filename\"_freq-1-withoutHF.tsv (Output2 Subtraction_Keywords_#3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597bc154",
   "metadata": {},
   "source": [
    "## Keyword_Frequency_SP_PDB: Frequency_#1\n",
    "\n",
    "### Description:\n",
    "\n",
    "The Word Frequency Analysis Tool is a Python script to analyze text data and generate frequency statistics for words within specific domains. The tool is primarily intended for processing TSV (Tab-Separated Values) files containing domain and word information.\n",
    "\n",
    "This Python script processes a TSV file containing information about virus proteins and their associated words. It extracts word frequency data for each virus protein domain, excluding specified common words. The resulting frequency data is then saved to a new TSV file for further analysis.\n",
    "\n",
    "Exclusion of Common and Irrelevant Words: The script allows for the exclusion of a predefined list of common English words, Greek alphabet characters, and specific user-defined words. These exclusions help focus the analysis on more meaningful content.\n",
    "\n",
    "Case Insensitivity and Punctuation Handling: The script processes text in a case-insensitive manner, ensuring that words are counted regardless of their capitalization. Additionally, it handles punctuation marks, such as commas and double quotes, ensuring they do not interfere with word recognition.\n",
    "\n",
    "Exclusion of Single Letters and Numbers: The tool automatically excludes words consisting of only a single letter or a single number, ensuring that the analysis focuses on meaningful terms.\n",
    "\n",
    "Excluded Words: The list of words to be excluded can be customized by modifying the exclude_words list within the script\n",
    "\n",
    "Example input: HCMV_UL18_domain_0.pdb Crystal structure of HLA DR52c 3c5j_B 7.74E-10 HCMV_UL18_domain_0.pdb Structure of chicken CD1-2 with bound fatty acid 3dbx_A 4.10E-11 HCMV_UL18_domain_0.pdb TCR complex 2wbj_F 7.32E-10 HCMV_UL18_domain_0.pdb NEONATAL FC RECEPTOR, PH 6.5\" 3fru_C 6.58E-12 HCMV_UL18_domain_0.pdb HLA-DR1 with GMF Influenza PB1 Peptide 6qza_BBB 1.14E-09 HCMV_UL18_domain_0.pdb Crystal structure of FcRn bound to UCB-84 6c98_C 6.23E-12 HCMV_UL18_domain_0.pdb immune receptor complex 6v15_B 8.18E-10 HCMV_UL18_domain_0.pdb Immune Receptor 4mdi_B 3.02E-10 [...]\n",
    "\n",
    "##### Output (XY_freq.tsv): The script generates an output TSV file with domain-specific word frequencies, which can be further analyzed or used for visualization. Both output-files will be used in Subtraction_Keywords_#3  and File_Merging_#4 as input. \n",
    "\n",
    "Example output: HCMV_UL18_domain_0 human(169), mhc(161), tcr(128), receptor(66), epitope(46), histocompatibility(45), hla(44), hiv-1(43), h-2db(40), chicken(39), binding(38), murine(36), virus(35), hla-dr1(34), major(32), [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee15d631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency data saved to: C:\\Users\\agbosse\\Desktop\\Test_File\\herpes_FL_against_pdb_nosymbol_hits_freq-1.tsv\n",
      "Frequency data saved to: C:\\Users\\agbosse\\Desktop\\Test_File\\herpes_FL_against_pdb_nosymbol_hits_freq.tsv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the file path manually\n",
    "file_path = r'<filename>.tsv'\n",
    "\n",
    "def is_valid_word(word):\n",
    "    return not (len(word) == 1 and (word.isalpha() or word.isdigit())) and not (len(word) == 2 and word.isdigit())\n",
    "\n",
    "def extract_word_frequency(filename, exclude_words, exclude_single_count=True):\n",
    "    domain_word_freq = {}\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split('\\t')\n",
    "            virus_protein_domain_parts = parts[0].split('_')\n",
    "            virus_protein_domain = '_'.join(virus_protein_domain_parts).replace('.pdb', '')  # Take all parts and exclude \".pdb\" extension\n",
    "            words = parts[2].split()\n",
    "            \n",
    "            if virus_protein_domain not in domain_word_freq:\n",
    "                domain_word_freq[virus_protein_domain] = {}\n",
    "            \n",
    "            for word in words:\n",
    "                # Convert both the word and exclude_words to lowercase for case insensitivity\n",
    "                word = word.lower().replace(',', '').replace('\"', '').replace('(',\"\").replace(')',\"\").replace(':', \"\")  # Remove commas, double quotesparentheses and quotes from word\n",
    "                if word not in exclude_words and is_valid_word(word):\n",
    "                    domain_word_freq[virus_protein_domain][word] = domain_word_freq[virus_protein_domain].get(word, 0) + 1\n",
    "\n",
    "    # Exclude words with only one count if exclude_single_count is True\n",
    "    if exclude_single_count:\n",
    "        for domain in domain_word_freq:\n",
    "            domain_word_freq[domain] = {word: count for word, count in domain_word_freq[domain].items() if count > 1}\n",
    "\n",
    "    return domain_word_freq\n",
    "\n",
    "def save_frequency_tsv(input_path, domain_word_freq, suffix=\"_freq\"):\n",
    "    output_folder, input_filename = os.path.split(input_path)\n",
    "    output_filename = os.path.splitext(input_filename)[0] + f\"{suffix}.tsv\"\n",
    "    output_path = os.path.join(output_folder, output_filename)\n",
    "\n",
    "    with open(output_path, 'w') as output_file:\n",
    "        sorted_domains = sorted(domain_word_freq.keys())  # Sort domains alphabetically\n",
    "\n",
    "        for domain in sorted_domains:\n",
    "            word_freq = domain_word_freq[domain]\n",
    "            sorted_freq = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "            result = [f'{key}({value})' for key, value in sorted_freq]\n",
    "            output_file.write(f'{domain}\\t{\", \".join(result)}\\n')\n",
    "\n",
    "def main():\n",
    "\n",
    "    if file_path:\n",
    "        # Add your list of excluded words here\n",
    "        exclude_words = [\"and\", \"alpha\", \"beta\", \"gamma\", \"delta\", \"epsilon\", \"zeta\", \"eta\", \"theta\", \"iota\", \n",
    "         \"kappa\", \"lambda\", \"mu\", \"nu\", \"xi\", \"omicron\", \"pi\", \"rho\", \"sigma\", \"tau\", \"upsilon\", \n",
    "         \"phi\", \"chi\", \"psi\", \"omega\", \"a\", \"an\", \"the\", \"in\", \"on\", \"to\", \"with\", \"for\", \"of\", \n",
    "         \"as\", \"by\", \"at\", \"ii\", \"cell\", \"protein\", \"probable\", \"motif\", \"chain\", \"type\", \"molecule\",\n",
    "         \"uncharacterized\", \"c-x-c\", \"c-c\", \"basic\", \"structure\", \"complex\", \"crystal\", \"bound\", \"fab\", \"domain\", \n",
    "         \"antibody\", \"mutant\", \"peptide\", \"cryo-em\", \"fragment\", \"complexed\", \"the\", \"compound\", \"atomic\", \"structural\",\n",
    "         \"by\", \"coli\", \"cryoem\", \"resolution\", \"its\" , \"form\", \"e.\", \"x-ray\", \"class\", \"structures\", \"-\", \"class\",\n",
    "         \"therapeutic\", \"deletion\", \"variant\", \"site\", \"functional\", \"reveal\", \"c1\", \"implications\", \"monoclonal\",\n",
    "         \"different\", \"allosteric\", \"ligand\", \"c-terminal\", \"low-ph\", \"escherichia\", \"e.coli\", \"between\", \"complexes.\",\n",
    "         \"(crystal\", \"engineered\", \"full\", \"xfel\", \"natural\", \"angstroms\", \"allosteric\", \"design\", \"discovery\", \"open\"\n",
    "         \"edition\", \"mode\", \"opposite\", \"novel\", \"region\", \"ligand-binding\", \"apo\", \"holoenzyme\", \"high\", \"full-length\",\n",
    "         \"loop\", \"angstrom\", \"template-primer\", \"based\", \"using\", \"from\", \"open\", \"conserved\", \"significance\", \"unit\",\n",
    "         \"loader\", \"neutralizing\", \"specificity\", \"substrate\", \"one\", \"inhibitor\", \"inhibitors\", \"after\", \"dehydration\",\n",
    "         \"de\", \"novo\", \"symmetry\", \"element\", \"iii\", \"ion\", \"\", \"herpes\", \"virus\", \"herpesvirus\", ]  \n",
    "        \n",
    "        # Save with \"_freq-1\" suffix (exclude single count)\n",
    "        domain_word_freq = extract_word_frequency(file_path, exclude_words)\n",
    "        save_frequency_tsv(file_path, domain_word_freq, suffix=\"_freq-1\")\n",
    "        print(f'Frequency data saved to: {os.path.splitext(file_path)[0]}_freq-1.tsv')\n",
    "\n",
    "        # Save with \"_freq\" suffix (do not exclude single count)\n",
    "        domain_word_freq_no_exclusion = extract_word_frequency(file_path, exclude_words, exclude_single_count=False)\n",
    "        save_frequency_tsv(file_path, domain_word_freq_no_exclusion, suffix=\"_freq\")\n",
    "        print(f'Frequency data saved to: {os.path.splitext(file_path)[0]}_freq.tsv')\n",
    "    else:\n",
    "        print(\"No input file selected.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17784e3c",
   "metadata": {},
   "source": [
    "## Keyword_Frequency_SP_PDB: Extract_Keywords_HomologyTable_#2\n",
    "\n",
    "Description:\n",
    "\n",
    "This Python script extracts keywords from a specified Excel file containing information about virus proteins and their associated abbreviations and descriptions. The output is a TSV (Tab-Separated Values) file with each row representing a virus protein domain and its corresponding set of keywords. The extraction process involves parsing the Excel file, combining virus names with protein names, and collecting keywords from the \"Abbreviation\" and \"Description\" columns.\n",
    "\n",
    "Example Input Structure (Excel file):\n",
    "<filename2>.xlsx\n",
    "\n",
    "Example Output Structure (TSV file):\n",
    "EBV_Protein1_Name      abb1, desc1, keyword1, keyword2, ...\n",
    "HSV_Protein1_Name      abb2, desc2, keyword3, keyword4, ...\n",
    "...\n",
    "\n",
    "##### Output-file will be used in Subtraction_Keywords_#3 as input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0242ef23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted keywords saved to: C:\\Users\\agbosse\\Desktop\\Test_File\\HerpesFolds_v6_9HHV_no-links_2023-11-30_TS_SAS_keywords.tsv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the file path manually\n",
    "input_file_path = r'<filename2>.xlsx'\n",
    "output_file_path = r'<filename2>_keywords.tsv'\n",
    "\n",
    "def extract_keywords_from_excel(filename):\n",
    "    domain_keywords = {}\n",
    "    \n",
    "    # Read Excel file into a DataFrame\n",
    "    df = pd.read_excel(filename, header=0)\n",
    "\n",
    "    # Iterate through rows in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        virus_name = None\n",
    "        \n",
    "        for col in df.columns[2:]:\n",
    "            virus_name = col.split('_')[0]\n",
    "            protein_name = row[col]\n",
    "\n",
    "            if pd.notna(protein_name):\n",
    "                # Take only the first part of the protein name\n",
    "                protein_name = protein_name.split()[0].replace(',', '').replace('\"', '').replace('(', '').replace(')', '').replace(':', '')\n",
    "\n",
    "                # Assign virus name to the protein name\n",
    "                virus_protein_domain = f\"{virus_name}_{protein_name}\"\n",
    "                \n",
    "                if virus_protein_domain not in domain_keywords:\n",
    "                    domain_keywords[virus_protein_domain] = set()\n",
    "                \n",
    "                # Assign abbreviation and description\n",
    "                abbreviation = str(row['Abbreviation']).lower().replace(',', '').replace('\"', '').replace('(', '').replace(')', '').replace(':', '')\n",
    "                description = str(row['Description']).lower().replace(',', '').replace('\"', '').replace('(', '').replace(')', '').replace(':', '')\n",
    "                \n",
    "                # Split keywords if separated by a space\n",
    "                keywords = abbreviation.split() + description.split()\n",
    "                \n",
    "                domain_keywords[virus_protein_domain].update(keywords)\n",
    "\n",
    "    return domain_keywords\n",
    "\n",
    "def save_keywords_tsv(output_path, domain_keywords):\n",
    "    with open(output_path, 'w') as output_file:\n",
    "        # Sort the domain_keywords alphabetically based on the first column\n",
    "        sorted_domains = sorted(domain_keywords.keys())\n",
    "        \n",
    "        for domain in sorted_domains:\n",
    "            keywords_str = ', '.join(domain_keywords[domain])\n",
    "            output_file.write(f'{domain}\\t{keywords_str}\\n')\n",
    "\n",
    "def main():\n",
    "\n",
    "    if input_file_path:\n",
    "        domain_keywords = extract_keywords_from_excel(input_file_path)\n",
    "\n",
    "        # Save the extracted keywords to a TSV file\n",
    "        save_keywords_tsv(output_file_path, domain_keywords)\n",
    "        print(f'Extracted keywords saved to: {output_file_path}')\n",
    "    else:\n",
    "        print(\"No input file selected.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377549a7",
   "metadata": {},
   "source": [
    "## Keyword_Frequency_SP_PDB: Subtraction_Keywords_#3\n",
    "\n",
    "Description:\n",
    "\n",
    "This Python script #3 processes two TSV (Tab-Separated Values) files: \n",
    "one containing information about virus proteins and their associated keywords (\"Herpesfolds Homolog Table\" TSV, output from script #2), \n",
    "and the other containing frequency information about these virus_protein_domain_number and their keywords with counts (\"Keyword Freq\" TSV, output from script #1). \n",
    "\n",
    "The goal is to subtract keywords associated with virus proteins in the \"Herpesfolds Homolog Table\" TSV from the corresponding entries in the \"Keyword Freq\" TSV. The output is a new TSV file containing the virus proteins along with the remaining keywords and their counts.\n",
    "\n",
    "#### Example Input Structure (\"Herpesfolds Homolog Table\" TSV - output from cell #):\n",
    "EBV_BKRF3     udg, glycosylase, uracil-dna, ung\n",
    "EBV_BALF5     dna, dpol, polymerase\n",
    "\n",
    "#### Example Input Structure (\"Keyword Freq\" TSV - output from cell #):\n",
    "EBV_BKRF3_domain_0     uracil-dna(391), glycosylase(391)\n",
    "EBV_BALF5_domain_0     dna(82), polymerase(82), subunit(53), catalytic(51), polb(2)\n",
    "\n",
    "#### Example Output Structure:\n",
    "EBV_BKRF3_domain_0     \n",
    "EBV_BALF5_domain_0     subunit(53), catalytic(51), polb(2)\n",
    "\n",
    "In the output, keywords associated with virus proteins from the \"Herpesfolds\" TSV are subtracted from the corresponding entries in the \"Freq\" TSV. The resulting keywords, along with their counts, are retained in the output. The script ensures that the counts are accurately preserved during the subtraction process. The output is organized in the same format as the \"Freq\" TSV, with each line representing a virus protein domain and its associated keywords and counts.\n",
    "\n",
    "##### Output-files will be used in File_Merging_#4 as input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ba56148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output data saved to: C:\\Users\\agbosse\\Desktop\\Test_File\\herpes_FL_against_pdb_nosymbol_hits_freq-withoutHF.tsv\n",
      "Output data saved to: C:\\Users\\agbosse\\Desktop\\Test_File\\herpes_FL_against_pdb_nosymbol_hits_freq-1-withoutHF.tsv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# # Define the input file path manually\n",
    "freq_tsv_path_1 = r'<filename>_freq.tsv'\n",
    "freq_tsv_path_2 = r'<filename>_freq-1.tsv'\n",
    "herpesfolds_tsv_path = r'<filename2>_keywords.tsv'\n",
    "\n",
    "# Output file paths\n",
    "output_tsv_path_1 = r'<filename>_freq-withoutHF.tsv'\n",
    "output_tsv_path_2 = r'<filename>_freq-1-withoutHF.tsv'\n",
    "\n",
    "def subtract_keywords(herpesfolds_row, freq_row):\n",
    "    # Extract keywords from Herpesfolds row and format them\n",
    "    herpesfolds_keywords = set(herpesfolds_row[1].split(', '))\n",
    "    \n",
    "    # Extract keywords and counts from Freq row and format them\n",
    "    freq_keywords_with_counts = [word.split('(') if '(' in word else (word, '') for word in freq_row[1].split(', ')]\n",
    "    \n",
    "    # List to store subtracted keywords\n",
    "    subtracted_keywords = []\n",
    "\n",
    "    # Iterate over keywords and counts in Freq row\n",
    "    for word, count in freq_keywords_with_counts:\n",
    "        # Check if the keyword is not present in Herpesfolds keywords\n",
    "        if word not in herpesfolds_keywords and word != '':\n",
    "            # Append the keyword and its count to the subtracted_keywords list\n",
    "            subtracted_keywords.append(f'{word}({count})')\n",
    "\n",
    "    # Return the original virus_protein combination and the subtracted keywords\n",
    "    return freq_row[0], ', '.join(subtracted_keywords)\n",
    "\n",
    "def process_files(freq_tsv_path, herpesfolds_tsv_path, output_tsv_path):\n",
    "    # Dictionary to store unique rows based on their keys\n",
    "    output_dict = {}\n",
    "\n",
    "    # Read Freq TSV file into a list of rows\n",
    "    with open(freq_tsv_path, 'r', newline='', encoding='utf-8') as freq_file:\n",
    "        freq_reader = csv.reader(freq_file, delimiter='\\t')\n",
    "        freq_rows = list(freq_reader)\n",
    "\n",
    "    # Read Herpesfolds TSV file into a list of rows\n",
    "    with open(herpesfolds_tsv_path, 'r', newline='', encoding='utf-8') as herpesfolds_file:\n",
    "        herpesfolds_reader = csv.reader(herpesfolds_file, delimiter='\\t')\n",
    "        herpesfolds_rows = list(herpesfolds_reader)\n",
    "\n",
    "    # Iterate over Herpesfolds and Freq rows to perform subtraction\n",
    "    for herpesfolds_row in herpesfolds_rows:\n",
    "        for freq_row in freq_rows:\n",
    "            if herpesfolds_row[0] in freq_row[0]:\n",
    "                # Call subtract_keywords function and store the result in the dictionary\n",
    "                key, value = subtract_keywords(herpesfolds_row, freq_row)\n",
    "                output_dict[key] = value\n",
    "\n",
    "    # Convert the dictionary to a list before sorting and writing to the output file\n",
    "    output_rows_list = sorted([(key, value) for key, value in output_dict.items()], key=lambda x: x[0])\n",
    "\n",
    "    # Write the sorted output list to the output TSV file\n",
    "    with open(output_tsv_path, 'w', newline='', encoding='utf-8') as output_file:\n",
    "        output_writer = csv.writer(output_file, delimiter='\\t')\n",
    "        \n",
    "        # Iterate over output rows and write them to the file\n",
    "        for key, value in output_rows_list:\n",
    "            # Correctly format the output to avoid double closing parenthesis\n",
    "            output_writer.writerow([key, value.replace('))', ')')])\n",
    "\n",
    "    # Print the output file path when saved\n",
    "    print(f'Output data saved to: {output_tsv_path}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Call the process_files function for the first input\n",
    "    process_files(freq_tsv_path_1, herpesfolds_tsv_path, output_tsv_path_1)\n",
    "\n",
    "    # Call the process_files function for the second input\n",
    "    process_files(freq_tsv_path_2, herpesfolds_tsv_path, output_tsv_path_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05c0eb6",
   "metadata": {},
   "source": [
    "## Keyword_Frequency_SP_PDB: File_Merging_#4\n",
    "\n",
    "The Python script merge_columns.py merges specific columns from three TSV files. It extracts the first two columns from the first file, the second column from the second file, and the second column from the third file. The merged data is saved with headers in a new TSV file named after the first input file, suffixed \"_HF_HF-1.tsv\".\n",
    "\n",
    "Input Example Files:\n",
    "\n",
    "    <filename>_freq.tsv: Extracts first two columns.\n",
    "    <filename>_freq-withoutHF.tsv: Extracts the second column.\n",
    "    <filename>_freq-1-withoutHF.tsv: Extracts the second column.\n",
    "\n",
    "Output Example File:\n",
    "\n",
    "    Merged data with headers saved as <filename>_freq_HF_HF-1.tsv.\n",
    "\n",
    "Columns in Example Output File:\n",
    "\n",
    "    Virus_protein: First column, virus protein information.\n",
    "    Keywords: Second column, keywords from the first file.\n",
    "    Keywords without HomologyTable: Third column, keywords from the second file.\n",
    "    Keywords without HomologyTable and single keywords: Fourth column, keywords from the third file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09832529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data with headers saved to: C:\\Users\\agbosse\\Desktop\\Test_File\\herpes_FL_against_pdb_nosymbol_hits_freq_HF_HF-1.tsv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# Paths to input and output files\n",
    "file1_path = r'<filename>_freq.tsv'\n",
    "file2_path = r'<filename>_freq-withoutHF.tsv'\n",
    "file3_path = r'<filename>_freq-1-withoutHF.tsv'\n",
    "    \n",
    "def merge_columns(file1_path, file2_path, file3_path, output_path):\n",
    "    data = []\n",
    "\n",
    "    # Read the first two columns from the first file\n",
    "    with open(file1_path, 'r', newline='', encoding='utf-8') as file1:\n",
    "        reader1 = csv.reader(file1, delimiter='\\t')\n",
    "        data = [row[:2] for row in reader1]\n",
    "\n",
    "    # Read the third column from the second file and append it to the data\n",
    "    with open(file2_path, 'r', newline='', encoding='utf-8') as file2:\n",
    "        reader2 = csv.reader(file2, delimiter='\\t')\n",
    "        for i, row in enumerate(reader2):\n",
    "            if i < len(data):\n",
    "                data[i].append(row[1])\n",
    "\n",
    "    # Read the fourth column from the third file and append it to the data\n",
    "    with open(file3_path, 'r', newline='', encoding='utf-8') as file3:\n",
    "        reader3 = csv.reader(file3, delimiter='\\t')\n",
    "        for i, row in enumerate(reader3):\n",
    "            if i < len(data):\n",
    "                data[i].append(row[1])\n",
    "\n",
    "    # Insert headers\n",
    "    headers = [\"Virus_protein\", \"Keywords\", \"Keywords without HomologyTable\", \"Keywords without HomologyTable and single keywords\"]\n",
    "    data.insert(0, headers)\n",
    "\n",
    "    # Save the merged data to the output file\n",
    "    with open(output_path, 'w', newline='', encoding='utf-8') as output_file:\n",
    "        writer = csv.writer(output_file, delimiter='\\t')\n",
    "        writer.writerows(data)\n",
    "\n",
    "    # Print the output file path when saved\n",
    "    print(f'Merged data with headers saved to: {output_path}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Generate the output file path based on the first file\n",
    "    output_path = os.path.splitext(file1_path)[0] + \"_HF_HF-1.tsv\"\n",
    "\n",
    "    # Call the merge_columns function with the provided paths\n",
    "    merge_columns(file1_path, file2_path, file3_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5755803e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
